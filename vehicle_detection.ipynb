{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# loads an image into a numpy array and scales it to 255 if necessary\n",
    "def load_img(file):\n",
    "    image = mpimg.imread(file)\n",
    "    if file[-4:] == '.png':\n",
    "        image = np.uint8(image * 255)\n",
    "    #if file[-4:] == '.jpg':\n",
    "    #    image = image.astype(np.float32)/255\n",
    "    return image\n",
    "\n",
    "# plots an array of images into an image matrix\n",
    "def plot_image_array(images, titles = [], ncols = 2, nrows = -1, fig_width = 20, fig_row_height = 4.5):\n",
    "    if nrows <= 0:\n",
    "        nrows = math.ceil(len(images) / 2)\n",
    "    fig = plt.figure(figsize=(fig_width, nrows * fig_row_height))\n",
    "    for idx, img in enumerate(images):\n",
    "        if idx >= (nrows * ncols):\n",
    "            break\n",
    "        a=fig.add_subplot(nrows, ncols, idx + 1)\n",
    "        if len(img.shape) == 2:\n",
    "            imgplot = plt.imshow(img, cmap = 'gray' if len(img.shape) == 2 else None)\n",
    "        else:\n",
    "            imgplot = plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))     \n",
    "            imgplot = plt.imshow(img)\n",
    "        if(len(titles) >= idx):\n",
    "            a.set_title(titles[idx])\n",
    "    fig.tight_layout()\n",
    "            \n",
    "# saves an array of images to a folder         \n",
    "def save_images(folder, images, names):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for img, fname in zip(images, names):\n",
    "        fname = fname.replace('/', '_')\n",
    "        fname = fname.replace(' ', '_')\n",
    "        fname = fname.replace(':', '_')\n",
    "        fname = fname.replace('.jpg', '')\n",
    "        p = os.path.join(folder, os.path.split(fname)[-1])\n",
    "\n",
    "        p += '.jpg'\n",
    "        if np.max(img) == 1:\n",
    "            img = img * 255\n",
    "        #print('saving', p)\n",
    "        cv2.imwrite(p, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834 samples loaded for category GTI_Far\n",
      "909 samples loaded for category GTI_Left\n",
      "419 samples loaded for category GTI_MiddleClose\n",
      "664 samples loaded for category GTI_Right\n",
      "5966 samples loaded for category KITTI_extracted\n",
      "176 samples loaded for category Udacity\n",
      "8968 samples loaded from ./training_data/vehicles \n",
      "\n",
      "5068 samples loaded for category Extras\n",
      "3900 samples loaded for category GTI\n",
      "8968 samples loaded from ./training_data/non-vehicles \n",
      "\n",
      "1598 total samples loaded\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "loc_vehicles = './training_data/vehicles'\n",
    "loc_non_vehicles = './training_data/non-vehicles'\n",
    "\n",
    "# reurns a dictionary with an entry for each subfolder of folder \n",
    "# and a list with all image files for each category\n",
    "def load_training_dictionary(folder):\n",
    "    result = {}\n",
    "    num_samples = 0\n",
    "    categories = [dI for dI in os.listdir(folder) if os.path.isdir(os.path.join(folder, dI))]\n",
    "    for c in categories:\n",
    "        image_files = glob.glob(os.path.normpath(os.path.join(folder, c, '*.png')))\n",
    "        num_samples += len(image_files)\n",
    "        result[c] = image_files\n",
    "        print(len(image_files), 'samples loaded for category', c)\n",
    "        \n",
    "    print(num_samples, 'samples loaded from', folder, '\\n')\n",
    "    return result, num_samples\n",
    "\n",
    "def create_grouped_label_data(sample_dicts, group_size=12, label_size=None):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    categories = []\n",
    "    groups = []\n",
    "    \n",
    "    group = 0\n",
    "    for label in range(2):\n",
    "        cat_id = label * 10\n",
    "        \n",
    "        cat_size = None\n",
    "        if label_size:\n",
    "            cat_size = np.int32(label_size / len(sample_dicts[label].keys()))\n",
    "            \n",
    "        for category in sample_dicts[label]:\n",
    "            d = sample_dicts[label][category][:cat_size]\n",
    "            samples += d\n",
    "            labels += list(np.repeat(label, len(d)))\n",
    "            categories += list(np.repeat(cat_id, len(d)))\n",
    "            n_groups = len(d) // group_size\n",
    "            n_remaining = len(d) % group_size\n",
    "            groups += list(np.repeat(np.arange(group, group + n_groups), group_size))\n",
    "            group += n_groups\n",
    "            \n",
    "            if n_remaining > 0:\n",
    "                groups += list(np.repeat(group + n_groups, n_remaining))\n",
    "                group += 1\n",
    "\n",
    "            cat_id += 1\n",
    "    return {'samples': samples, \n",
    "            'labels': np.array(labels), \n",
    "            'categories': np.array(categories), \n",
    "            'groups': np.array(groups)}\n",
    "            \n",
    "            \n",
    "dict_vehicles, num_vehicles = load_training_dictionary(loc_vehicles)\n",
    "dict_non_vehicles, num_non_vehicles = load_training_dictionary(loc_non_vehicles)\n",
    "\n",
    "data = create_grouped_label_data((dict_vehicles, dict_non_vehicles), label_size = 800)\n",
    "print(len(data['samples']), 'total samples loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling shape: (1598, 8460)\n",
      "removing unimportant features\n",
      "(1598, 8460)\n",
      "(1598, 8460)\n",
      "Training SVM using cross validation\n",
      "Accuracy: 0.989 (+/- 0.0081)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert color\n",
    "def convert_color(image, color_space='RGB'):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            print('color space not recognized')\n",
    "            feature_image = np.copy(image) \n",
    "    else: \n",
    "        feature_image = np.copy(image)   \n",
    "    return feature_image\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, hog_channels=[0, 1, 2], feature_vec=True):\n",
    "    hog_features = []\n",
    "    for channel in hog_channels:\n",
    "        hog_features.append(hog(img[:,:,channel], orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=False, feature_vector=False))\n",
    "        \n",
    "    if feature_vec:\n",
    "        return np.ravel(hog_features)\n",
    "    else:\n",
    "        return np.dstack(hog_features)\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=32):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, (size, size)).ravel()\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(image, color_space='RGB', spatial_size=32,\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2,\n",
    "                        hog_channels=[0, 1, 2],\n",
    "                        hog_features=None,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "\n",
    "    # apply color conversion if other than 'RGB'\n",
    "    feature_image = convert_color(image, color_space=color_space)\n",
    "\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        features.append(spatial_features)\n",
    "    if hist_feat == True:\n",
    "        # Apply color_hist()\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        features.append(hist_features)\n",
    "    if hog_feat == True:\n",
    "        if hog_features is None:\n",
    "            hog_features = get_hog_features(feature_image, orient, pix_per_cell, cell_per_block, hog_channels, feature_vec=True)\n",
    "        \n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(hog_features)\n",
    "                          \n",
    "    # Return list of feature vectors\n",
    "    return np.concatenate(features)\n",
    "    \n",
    "def create_feature_list(data):\n",
    "    features = []                  \n",
    "    for file in data['samples']:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = load_img(file)\n",
    "        features.append(extract_features(image, **data['params']))\n",
    "        \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack(features).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    data['features'] = scaled_X\n",
    "    data['scaler'] = X_scaler\n",
    "\n",
    "\n",
    "#### LOAD TRAINING FEATURES ####\n",
    "data['params'] = {'color_space': 'LUV',\n",
    "                  'spatial_size': 32, \n",
    "                  'hist_bins': 32, \n",
    "                  'orient': 9, \n",
    "                  'pix_per_cell': 8, \n",
    "                  'cell_per_block': 2, \n",
    "                  'hog_channels': [0, 1, 2],\n",
    "                  'spatial_feat': True,\n",
    "                  'hist_feat': True,\n",
    "                  'hog_feat': True}\n",
    "\n",
    "create_feature_list(data)\n",
    "\n",
    "#### TESTING ####\n",
    "print('removing unimportant features')\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "print(data['features'].shape)\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(data['features'], data['labels'])\n",
    "#clf.feature_importances_  \n",
    "\n",
    "data['reduction'] = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "#data['features'] = data['reduction'].transform(data['features'])\n",
    "print(data['features'] .shape)               \n",
    "\n",
    "print('Training SVM using cross validation')\n",
    "data['svc'] = svm.SVC(kernel='linear', C=1)\n",
    "cv = GroupKFold(n_splits=3)\n",
    "score = cross_val_score(data['svc'], data['features'], data['labels'], groups=data['groups'], scoring='f1_macro', cv=cv)\n",
    "print(\"Accuracy: {:0.3f} (+/- {:0.4f})\".format(score.mean(), score.std() * 2))\n",
    "data['svc'].fit(data['features'], data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for train and test: 800 798 \n",
      "\n",
      "Distribution vehicles/non-vehicles (train, test):\n",
      " [ 0.515  0.485] \n",
      " [ 0.48370927  0.51629073] \n",
      "\n",
      "Distribution sub-categories (train, test):\n",
      " [ 0.09125  0.09     0.07625  0.075    0.09125  0.01825  0.24     0.245  ] \n",
      " [ 0.07518797  0.0764411   0.09022556  0.0914787   0.07518797  0.01503759\n",
      "  0.26065163  0.2556391 ] \n",
      "\n",
      "Shared groups between train and test: set() \n",
      "----------------------------------------------\n",
      "\n",
      "Number of samples for train and test: 798 800 \n",
      "\n",
      "Distribution vehicles/non-vehicles (train, test):\n",
      " [ 0.48370927  0.51629073] \n",
      " [ 0.515  0.485] \n",
      "\n",
      "Distribution sub-categories (train, test):\n",
      " [ 0.07518797  0.0764411   0.09022556  0.0914787   0.07518797  0.01503759\n",
      "  0.26065163  0.2556391 ] \n",
      " [ 0.09125  0.09     0.07625  0.075    0.09125  0.01825  0.24     0.245  ] \n",
      "\n",
      "Shared groups between train and test: set() \n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "\n",
    "for train_index, test_index in group_kfold.split(data['features'], data['labels'], data['groups']):\n",
    "    X_train, X_test = data['features'][train_index], data['features'][test_index]\n",
    "    y_train, y_test = data['labels'][train_index], data['labels'][test_index]\n",
    "    c_train, c_test = data['categories'][train_index], data['categories'][test_index]\n",
    "    g_train, g_test = data['groups'][train_index], data['groups'][test_index]\n",
    "      \n",
    "    # print sizes of train and test\n",
    "    print('Number of samples for train and test:', len(y_train), len(y_test), '\\n')        \n",
    "        \n",
    "    # check if vehicles and non vehicles are roughly 0.5 for train and test\n",
    "    hy_train = np.histogram(y_train, bins=[-0.5, 0.5, 1.5], density=True)\n",
    "    hy_test = np.histogram(y_test, bins=[-0.5, 0.5, 1.5], density=True)\n",
    "    print('Distribution vehicles/non-vehicles (train, test):\\n', \n",
    "          hy_train[0], '\\n', \n",
    "          hy_test[0], '\\n')\n",
    "    \n",
    "    # check if categories are equally distributed over train and test\n",
    "    c_bins = [ v - 0.5 for v in sorted(list(set(c_train).union(set(c_test))))]\n",
    "    c_bins.append(c_bins[-1] + 1)\n",
    "    hc_train = np.histogram(c_train, bins=c_bins, density=True)\n",
    "    hc_test = np.histogram(c_test, bins=c_bins, density=True)\n",
    "    print('Distribution sub-categories (train, test):\\n', \n",
    "          hc_train[0], '\\n', \n",
    "          hc_test[0], '\\n')\n",
    "    \n",
    "    #check if groups aren't split over train and test\n",
    "    sg_train = set(g_train)\n",
    "    sg_test = set(g_test)\n",
    "    print('Shared groups between train and test:', \n",
    "          sg_train.intersection(sg_test), \n",
    "          '\\n----------------------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RGB: 0.956 (+/- 0.0051)\n",
      "Accuracy for HSV: 0.971 (+/- 0.0076)\n",
      "Accuracy for LUV: 0.976 (+/- 0.0113)\n",
      "Accuracy for HLS: 0.976 (+/- 0.0038)\n",
      "Accuracy for YUV: 0.976 (+/- 0.0113)\n",
      "Accuracy for YCrCb: 0.975 (+/- 0.0051)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "color_spaces = ['RGB', 'HSV', 'LUV', 'HLS', 'YUV', 'YCrCb']\n",
    "\n",
    "for c in color_spaces:\n",
    "    clf = svm.SVC(kernel='linear', C=1)\n",
    "    cv = GroupKFold(n_splits=2)\n",
    "    create_feature_list(data, color_space=c, spatial_size=32,\n",
    "                                        hist_bins=32, orient=9, \n",
    "                                        pix_per_cell=8, cell_per_block=2, hog_channels=[0, 1, 2],\n",
    "                                        spatial_feat=False, hist_feat=False, hog_feat=True)\n",
    "    score = cross_val_score(clf, data['features'], data['labels'], groups=data['groups'], cv=cv)\n",
    "    print(\"Accuracy for {}: {:0.3f} (+/- {:0.4f})\".format(c, score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.975 (+/-0.004) for {'C': 1, 'kernel': 'linear'}\n",
      "0.975 (+/-0.004) for {'C': 10, 'kernel': 'linear'}\n",
      "0.975 (+/-0.004) for {'C': 100, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parameters = {'kernel': ['linear'], 'C': [1, 10, 100]}\n",
    "print(\"# Tuning hyper-parameters for f1\")\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=cv,\n",
    "                   scoring='f1')\n",
    "clf.fit(data['features'], data['labels'], groups=data['groups'])\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "#print(\"Detailed classification report:\")\n",
    "#print()\n",
    "#print(\"The model is trained on the full development set.\")\n",
    "#print(\"The scores are computed on the full evaluation set.\")\n",
    "#print()\n",
    "#y_pred = clf.predict(data['features'])\n",
    "#print(classification_report(data['labels'], y_pred))\n",
    "#print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,7704) (8460,) (1,7704) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-5e877deca7ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0mtest_hog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mout_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_cars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mystart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mystop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'svc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scaler'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0mtest_hog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[0mplot_image_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_hog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-5e877deca7ac>\u001b[0m in \u001b[0;36mfind_cars\u001b[1;34m(img, ystart, ystop, scale, svc, X_scaler, feature_params)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;31m# Scale features and make a prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[1;31m#test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mtest_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,7704) (8460,) (1,7704) "
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, feature_params):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, feature_params['color_space'])\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    #ch1 = ctrans_tosearch[:,:,0]\n",
    "    #ch2 = ctrans_tosearch[:,:,1]\n",
    "    #ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (img.shape[1] // feature_params['pix_per_cell']) - feature_params['cell_per_block'] + 1\n",
    "    nyblocks = (img.shape[0] // feature_params['pix_per_cell']) - feature_params['cell_per_block'] + 1 \n",
    "    nfeat_per_block = feature_params['orient']*feature_params['cell_per_block']**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // feature_params['pix_per_cell']) - feature_params['cell_per_block'] + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    \n",
    "    hog = get_hog_features(ctrans_tosearch, \n",
    "                           feature_params['orient'], \n",
    "                           feature_params['pix_per_cell'], \n",
    "                           feature_params['cell_per_block'], \n",
    "                           feature_params['hog_channels'], \n",
    "                           feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            #hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            #hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            #hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            sub_hog = hog[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window, ]\n",
    "            hog_features = np.rollaxis(sub_hog, 2, 0).ravel()\n",
    "\n",
    "            xleft = xpos*feature_params['pix_per_cell']\n",
    "            ytop = ypos*feature_params['pix_per_cell']\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (window, window))\n",
    "          \n",
    "            # Get color features\n",
    "            subfeatures = extract_features(subimg, hog_features=hog_features, **feature_params)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(subfeatures.reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                \n",
    "    return draw_img    \n",
    "\n",
    "\n",
    "image_files = glob.glob('test_images/test*.jpg')\n",
    "test = []\n",
    "test_n = []\n",
    "for idx, fname in enumerate(image_files):\n",
    "    test.append(load_img(fname))\n",
    "    test_n.append(fname)\n",
    "        \n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1.5\n",
    "\n",
    "test_hog = []\n",
    "for i in range(len(test)):\n",
    "    out_img = find_cars(test[i], ystart, ystop, scale, data['svc'], data['scaler'], data['params'])\n",
    "    test_hog.append(out_img)\n",
    "plot_image_array(test_hog, test_n, ncols=3)   \n",
    "\n",
    "#plt.imshow(out_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
